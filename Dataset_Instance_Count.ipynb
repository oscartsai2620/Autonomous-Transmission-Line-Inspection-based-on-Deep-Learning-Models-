{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "45da81fa-9e8e-409f-b831-536e00312d2b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/mnt/sdb/home/si25_osts0525/UAV_Inspection_System\n"
     ]
    }
   ],
   "source": [
    "!pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "40ea1cb9-335f-4340-89b1-8b4583d33d0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "from collections import Counter\n",
    "\n",
    "def count_labels(label_dir: Path) -> Counter:\n",
    "    \"\"\"Count first integers (class IDs) in all .txt label files under label_dir.\"\"\"\n",
    "    counter = Counter()\n",
    "    for txt_path in label_dir.glob(\"*.txt\"):\n",
    "        with txt_path.open() as f:\n",
    "            for line in f:\n",
    "                line = line.strip()\n",
    "                if not line:\n",
    "                    continue\n",
    "                cls_id = int(line.split()[0])   # first token is the class id\n",
    "                counter[cls_id] += 1\n",
    "    return counter\n",
    "\n",
    "def compute_count(dataset):\n",
    "    # ------------------------------------------------------------------\n",
    "    # 1.  CONFIGURE THESE TWO THINGS\n",
    "    # ------------------------------------------------------------------\n",
    "    print(f\"\\n======Instance Count for {dataset} Dataset======\")\n",
    "    dataset_root = Path(f\"dataset/{dataset}\")   # adjust if your path differs\n",
    "    class_names = [\n",
    "        \"Birdnest\",\n",
    "        \"Broken_Insulator\",\n",
    "        \"Defective_Damper\",\n",
    "        \"Flashover_Insulator\",\n",
    "        \"Normal_Damper\",\n",
    "        \"Normal_Insulators\",\n",
    "        \"Self-Exploded_Insulator\",\n",
    "    ]\n",
    "    \n",
    "    total_counts = Counter()\n",
    "    \n",
    "    for split in (\"train\", \"val\", \"test\"):\n",
    "        lbl_dir = dataset_root / split / \"labels\"\n",
    "        if not lbl_dir.exists():\n",
    "            print(f\" {lbl_dir} not found — skipping.\")\n",
    "            continue\n",
    "        split_counts = count_labels(lbl_dir)\n",
    "        \n",
    "        # sort by class-id\n",
    "        sorted_split = {k: split_counts[k] for k in sorted(split_counts)}\n",
    "        print(f\"{split:<5s}: {dict(sorted_split)}  (files: {len(list(lbl_dir.glob('*.txt')))})\")\n",
    "        total_counts += split_counts\n",
    "    \n",
    "    print(f\"\\n====== TOTAL for {dataset} (train + val + test) ======\")\n",
    "    for cls_id in sorted(total_counts):\n",
    "        name = class_names[cls_id] if cls_id < len(class_names) else f\"cls_{cls_id}\"\n",
    "        print(f\"{cls_id:>2d} – {name:<20s}: {total_counts[cls_id]} instances\")\n",
    "    \n",
    "    print(f\"\\nGrand total objects: {sum(total_counts.values())}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "31c4e0ce-026c-42c9-b75e-26068f6eca7c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======Instance Count for source Dataset======\n",
      "train: {0: 272, 1: 137, 3: 50, 4: 2417, 5: 3889, 6: 138}  (files: 2776)\n",
      "val  : {0: 76, 1: 20, 3: 6, 4: 572, 5: 863, 6: 39}  (files: 595)\n",
      "test : {0: 60, 1: 32, 3: 10, 4: 464, 5: 833, 6: 37}  (files: 595)\n",
      "\n",
      "====== TOTAL for source (train + val + test) ======\n",
      " 0 – Birdnest            : 408 instances\n",
      " 1 – Broken_Insulator    : 189 instances\n",
      " 3 – Flashover_Insulator : 66 instances\n",
      " 4 – Normal_Damper       : 3453 instances\n",
      " 5 – Normal_Insulators   : 5585 instances\n",
      " 6 – Self-Exploded_Insulator: 214 instances\n",
      "\n",
      "Grand total objects: 9915\n",
      "\n",
      "======Instance Count for target Dataset======\n",
      "train: {0: 522, 1: 495, 2: 213, 3: 1027, 4: 3177, 5: 1798, 6: 1251}  (files: 2442)\n",
      "val  : {0: 102, 1: 126, 2: 60, 3: 180, 4: 590, 5: 351, 6: 249}  (files: 510)\n",
      "test : {0: 99, 1: 114, 2: 66, 3: 198, 4: 597, 5: 486, 6: 282}  (files: 537)\n",
      "\n",
      "====== TOTAL for target (train + val + test) ======\n",
      " 0 – Birdnest            : 723 instances\n",
      " 1 – Broken_Insulator    : 735 instances\n",
      " 2 – Defective_Damper    : 339 instances\n",
      " 3 – Flashover_Insulator : 1405 instances\n",
      " 4 – Normal_Damper       : 4364 instances\n",
      " 5 – Normal_Insulators   : 2635 instances\n",
      " 6 – Self-Exploded_Insulator: 1782 instances\n",
      "\n",
      "Grand total objects: 11983\n"
     ]
    }
   ],
   "source": [
    "compute_count(\"source\")\n",
    "compute_count(\"target\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
